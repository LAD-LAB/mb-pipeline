---
title: "Pipeline to phyloseq"
output:
  html_document:
    df_print: paged
---

## Setup

```{r}
# Load required R libraries, installing if necessary
# if (!require("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# (!require("devtools", quietly = TRUE))
#     install.packages("devtools")
# 
# devtools::install_github('ammararuby/MButils')
# devtools::install_github('jbisanz/qiime2R')
# BiocManager::install("phyloseq")
# BiocManager::install("dada2")
# BiocManager::install("ShortRead")
# devtools::install_github('jbisanz/qiime2R')
# install.packages('tidyverse')
# install.packages('taxonomizr')

library(here) # For relative paths
library(MButils)
library(phyloseq)
library(devtools)
library(qiime2R)
library(tidyverse)
library(taxonomizr)
```
## Download data (if you haven't already)
Example commands to download your data from the DCC.
### OPTION 1: Run count-reads locally
If you have not run count-reads.sh, you will need all the output files (the files are large and this may take a few minutes)
```{bash, eval=FALSE}
scp -r <netid>@dcc-login.oit.duke.edu:/path/to/qiime-dir /path/to/local/directory
```
Go to "Step 0"
### OPTION 2: Just download files needed for phyloseq
```{bash, eval=FALSE}
# If you ran count-reads.sh, you just need these files:
scp <netid>@dcc-login.oit.duke.edu:/path/to/4_denoised-table.qza
scp <netid>@dcc-login.oit.duke.edu:/path/to/4_denoised-seqs.qza
scp <netid>@dcc-login.oit.duke.edu:/path/to/track-pipeline.csv
```
You can skip to "Step 1"
## Read in data
```{r}
qiime.dir <- '/path/to/qiime-output-directory'
```

## Step 0) Extract read counts (skip if you already ran count-reads.sh)
```{r}
# Point to directory containing pipeline output
# Set variables for bash
Sys.setenv(QIIME_DIR = qiime.dir)
```
NOTE: If you ran the "count-reads" script, you can skip this step.
This should only be run once; if hanging at this step, you may need to go back and delete files or skip to code chunk below
```{bash engine.opts='-l'}
# Extract count information from QIIME2 visualization object
# Unzip the files if not already done
cd "$QIIME_DIR"

for f in [123]*.qzv; do
     unzip $f -d ${f%.qzv}
done
unzip 4_denoised-stats.qzv -d 4_denoised-stats

```


```{r}

# Read TSVs
count.fs <- 
     list.files(qiime.dir,
                pattern = 'per-sample-fastq-counts.tsv|metadata.tsv',
                recursive = TRUE,
                full.names = TRUE)
test=count.fs[1]
split_result=unlist(str_split(test,"/"))

count.files=c(seq_along(count.fs))
for (i in seq_along(count.fs)) {
  f=count.fs[i]
  split_result=unlist(str_split(f,"/")) # unzipped qiime directories go /name-of-qzv/random-numbers/data/file.tsv
  dirName=split_result[length(split_result) - 3] # so I can access what step of the pipeline the file came from by going back 3
  f=read_delim(f)
  if (dirName=='4_denoised-table') {
    break # this directory shouldn't have been unzipped but in case it was, skip it 
  }
  if (dirName=='4_denoised-stats') {
    f=f[-1,] %>%
      mutate(sample_ID=`sample-id`) %>%
      dplyr::select(sample_ID,filtered,denoised,merged,`non-chimeric`) 
    
  } 
  else {
  colnames(f)=str_replace_all(colnames(f),fixed(" "),"_")
  f$reverse_sequence_count=NULL
  colnames(f)[2]=dirName }
  if (i==1) {
    count.files=f
  } else {
    count.files=left_join(count.files,f,by='sample_ID')
  }
}
count.files
names(count.files) <- c('sample', 
                         'raw',
                         'adapter_trim',
                         'primer_trim',
                        'filtered',
                        'denoised',
                        'merged',
                        'non-chimeric')
count.files
write.csv(count.files,file.path(qiime.dir,
                                'track-pipeline.csv'))

```
## Step 1) QC 
If you already ran 'count-reads', skip to here
```{r}
count.files=file.path(qiime.dir,
                      'track-pipeline.csv') %>%
  read.csv()
```

```{r}
count.files %>%
  pivot_longer(names_to = 'step',values_to = 'count',cols=c('raw','adapter_trim','primer_trim')) %>%
  mutate(label=ifelse(sample=='Undetermined','Undetermined','Sample'),
         step=factor(step,levels=c('raw','adapter_trim','primer_trim'))) %>%
  ggplot(aes(x = step, 
                       y = count, 
                       by = sample, 
                       group = sample)) +
     geom_line(alpha = 0.5) +
     facet_wrap(~label, 
                scales = 'free_y') +
     labs(x = 'Pipeline step', 
          y = 'Reads', 
          title = '[DATE] MiniSeq run') +
     theme_bw() +
     theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Step 2) Make phyloseq object

### ASV tables

A few notes on QIIME2 output:
- Features in the ASV table features are a hash instead of a DNA sequence
- The table is organized as features x samples instead of samples x features

We'll pull these using QIIME2R functions to extract information from QIIME2 artifacts, join them together, and re-arrange as samples x features.
```{r}
qiime.asvtab <- 
     file.path(qiime.dir,
          '4_denoised-table.qza') %>% 
     read_qza()
```

```{r}
qiime.seqs <- 
     file.path(qiime.dir,
          '4_denoised-seqs.qza') %>% 
     read_qza()
```

```{r}
join_table_seqs <- function(feature_table, sequence_hash){
     # feature_table and sequence_hash are the result of reading in QIIME2
     # artifacts with QIIME2R
     
     # Make dataframe mapping from from hash to ASV
     sequence_hash <- 
          data.frame(asv = sequence_hash$data) %>% 
          rownames_to_column(var = 'hash')
     
     # Substitute hash for ASV in feature table
     feature_table <-
          feature_table$data %>% 
          data.frame() %>% 
          rownames_to_column(var = 'hash') %>% 
          left_join(sequence_hash) %>% 
          column_to_rownames(var = 'asv') %>% 
          dplyr::select(-hash) 
     
     # Transform rows and columns and repair plate-well names\
     feature_table <- t(feature_table) 
     
     # Repair names
     row.names(feature_table) <- gsub(pattern = 'X',
                                      replacement = '',
                                      row.names(feature_table))
     row.names(feature_table) <- gsub(pattern = '\\.',
                                      replacement = '-',
                                      row.names(feature_table))
          
     feature_table
}
```

```{r}
qiime.asvtab <- join_table_seqs(qiime.asvtab, qiime.seqs)
```

#### QC

We'll do a few quick QC steps here:
- First, we'll collapse sequences that are exact subsequences of each other with DADA2's `collapseNoMismatch` function.
- Second, we'll visualize the distribution of sequence lengths in the dataset.

```{r}
cat(ncol(qiime.asvtab), 'ASVs before collapsing\n')
qiime.asvtab <- dada2::collapseNoMismatch(qiime.asvtab)
cat(ncol(qiime.asvtab), 'ASVs after collapsing\n')
```

Visualize the distribution of sequence lengths

```{r}
lengths <- 
     data.frame(asv = colnames(qiime.asvtab),
                reads = colSums(qiime.asvtab)) |> 
     mutate(length = nchar(asv))
```

```{r}
# Histogram of sequence lengths
ggplot(lengths, aes(x = length)) +
     geom_histogram(binwidth = 5, boundary = 0) +
     geom_vline(xintercept = c(10, 143), # Reported range of trnL length
                color = 'red', 
                linetype = 'dashed') +
     labs(x = 'ASV length (bp)', y = 'Count') +
     theme_bw() +
     scale_x_continuous(minor_breaks = seq(0, 250, 10), 
                        breaks = seq(0, 250, 50))
```

### Taxonomy table

```{r}
# Using modified assignSpecies function from DADA2
# (only modifies format of returned data, not underlying assignment)
ref <- here('0_Methods', 'Reference','12SV5.fasta')
taxtab.species <- MButils::assignSpecies_mod(qiime.asvtab, 
                                             refFasta = ref, 
                                             tryRC = TRUE)
```

```{r}
# How many ASVs unassigned?
unassigned <- taxtab.species$asv[is.na(taxtab.species$Species)]

# Percentage of sequence variants
cat(100*(1 - (length(unassigned)/dim(qiime.asvtab)[2])), '% ASVs have an assigment\n')

# Percentage of reads mapping to these unassigned species
cat('These ASVs cover', 100*(1-sum(qiime.asvtab[, unassigned])/sum(qiime.asvtab)), '% of sequence reads in the dataset')
```

Now, look up full taxonomy for these assigned species using taxonomizr functions and SQL database.

For taxonomic assignment, we'll need a path to the SQL database of NCBI's taxonomy produced by R's taxonomizr package.  This is saved on Isilon (~70Gb).  You'll need to map the Isilon network drive to your computer and then point R to the right location. To do this on a Mac, open the application "Finder". At the top of your screen, click "Go". Click "Connect to Server." Now enter 'smb://duhsnas-pri.dhe.duke.edu/dusom_mgm-david/All_Staff' and connect. (You will need to enter your netID, password, and the passcode from Duo for 2-step authentication.) If you are on a Mac, you can then connect to the taxonomy file by using the path below:

```{r}
sql <- '/Volumes/All_Staff/localreference/ncbi_taxonomy/accessionTaxa.sql'
```

```{r}
# Separate accession from species name in our current list of assignments
taxtab.species <- separate(taxtab.species, 
                           Species,
                           into = c('accession', 'taxon'),
                           sep = ' ',
                           extra = 'merge')

head(taxtab.species)
```

```{r}
# Now look up full taxonomy
# First link accession to taxon ID
taxids <- 
     taxonomizr::accessionToTaxa(taxtab.species$accession,
                                 sql)
```

```{r}
# Then link taxon ID to full taxonomy
taxonomy.raw <- 
     taxonomizr::getRawTaxonomy(taxids, sql)
```

```{r}
# Pull desired levels from this structure
# Not working within getTaxonomy function
vars <- c("superkingdom", 
          "phylum", 
          "class", 
          "order", 
          "family", 
          "genus",
          "species",
          "subspecies",
          "varietas",
          "forma")

taxonomy <- data.frame(superkingdom = NULL,
                       phylum = NULL,
                       class = NULL,
                       order = NULL,
                       family = NULL,
                       genus = NULL,
                       species = NULL,
                       subspecies = NULL,
                       varietas = NULL,
                       forma = NULL)

# Define an empty row to be returned if no accession was looked up
empty <- rep(NA, 10)
names(empty) <- vars

acc <- function(i, taxonomy.raw, vars) {
     # If accession looked up, pull relevant columns and return it
     row.i <- 
          taxonomy.raw[[i]] %>% 
          t() %>% 
          data.frame() 
     
     # Pick columns we're interested in
     shared <- intersect(vars, names(row.i))
     row.i <- select(row.i, one_of(shared))
     row.i
}

# If not looked up, returne empty row
no_acc <- function() empty

for (i in seq_along(taxonomy.raw)){
     row.i <- 
          tryCatch(
               {
                    acc(i, taxonomy.raw, vars)
               }, 
               error = function(e) {
                    no_acc()
               }
          )

     taxonomy <- bind_rows(taxonomy, row.i)
}
```

```{r}
head(taxonomy)
```
```{r}
# Group these to their last common ancestor using taxonomizr's condenseTaxa function
ncol(qiime.asvtab)
assignments <- 
     taxonomizr::condenseTaxa(taxonomy,
                              groupings = taxtab.species$asv)
dim(assignments)
```

```{r}
# To what label are assignments made?
colSums(!is.na(assignments))/nrow(assignments)
```
### Make object

```{r}
ps <- 
     phyloseq(otu_table = otu_table(qiime.asvtab,
                                    taxa_are_rows = FALSE),
              tax_table = tax_table(assignments))

ps
```
# Step 3) Save
```{r}
ps %>%
  saveRDS(file=here('ps.rds'))
```

