---
title: "Pipeline to phyloseq"
output:
  html_document:
    df_print: paged
---

## Setup

```{r}
# Load required R libraries, installing if necessary
# if (!require("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# (!require("devtools", quietly = TRUE))
#     install.packages("devtools")
# 
# devtools::install_github('ammararuby/MButils')
# devtools::install_github('jbisanz/qiime2R')
# BiocManager::install("phyloseq")
# BiocManager::install("dada2")
# BiocManager::install("ShortRead")
# devtools::install_github('jbisanz/qiime2R')
# install.packages('tidyverse')
# install.packages('taxonomizr')
# install.packages('here')

library(here) # For relative paths
library(MButils)
library(phyloseq)
library(devtools)
library(qiime2R)
library(tidyverse)
library(taxonomizr)

join_table_seqs <- function(feature_table, sequence_hash){
     # feature_table and sequence_hash are the result of reading in QIIME2
     # artifacts with QIIME2R
     
     # Make dataframe mapping from from hash to ASV
     sequence_hash <- 
          data.frame(asv = sequence_hash$data) %>% 
          rownames_to_column(var = 'hash')
     
     # Substitute hash for ASV in feature table
     feature_table <-
          feature_table$data %>% 
          data.frame() %>% 
          rownames_to_column(var = 'hash') %>% 
          left_join(sequence_hash) %>% 
          column_to_rownames(var = 'asv') %>% 
          dplyr::select(-hash) 
     
     # Transform rows and columns and repair plate-well names\
     feature_table <- t(feature_table) 
     
     # Repair names
     row.names(feature_table) <- gsub(pattern = 'X',
                                      replacement = '',
                                      row.names(feature_table))
     row.names(feature_table) <- gsub(pattern = '\\.',
                                      replacement = '-',
                                      row.names(feature_table))
          
     feature_table
}
```
## Download data (if you haven't already)
Example commands to download your data from the DCC.
### OPTION 1: Run count-reads locally
If you have not run count-reads.sh, you will need all the output files (the files are large and this may take a few minutes)
```{bash, eval=FALSE}
scp -r <netid>@dcc-login.oit.duke.edu:/path/to/qiime-dir /path/to/local/directory
```
Go to "Step 0"
### OPTION 2: Just download files needed for phyloseq
```{bash, eval=FALSE}
# If you ran count-reads.sh, you just need these files:
# scp <netid>@dcc-login.oit.duke.edu:/path/to/4_denoised-table.qza /path/to/qiime-dir
# scp <netid>@dcc-login.oit.duke.edu:/path/to/4_denoised-seqs.qza /path/to/qiime-dir
# scp <netid>@dcc-login.oit.duke.edu:/path/to/track-pipeline.csv /path/to/qiime-dir
```

This code chunk will write the commands for you if you enter the path to the pipeline results on the DCC (dcc.qiime.dir) and the path to where you would like to store the output files locally (qiime.dir) and your netid
```{r}
dcc.qiime.dir='/hpc/group/ldavidlab/users/tjk30/Cambodia-12SV5-20230803/20230825_results/20230825_12SV5_output'
qiime.dir <- '/Users/tjk30/Library/CloudStorage/Box-Box/project_davidlab/LAD_LAB_Personnel/Teresa_M/1_Infant-Metabarcoding/2023-08-07_12SV5-Cambodia-HOPE'
netid='tjk30'
print(paste0('scp ',netid,'@dcc-login.oit.duke.edu:',dcc.qiime.dir,'/4_denoised-table.qza ',qiime.dir))
print(paste0('scp ',netid,'@dcc-login.oit.duke.edu:',dcc.qiime.dir,'/4_denoised-seqs.qza ',qiime.dir))
print(paste0('scp ',netid,'@dcc-login.oit.duke.edu:',dcc.qiime.dir,'/track-pipeline.csv ',qiime.dir))
```


You can skip to "Step 1"

## Step 0) Extract read counts (skip if you already ran count-reads.sh)

### Read in data
```{r}
qiime.dir <- '/path/to/qiime-output-directory'
```

```{r}
# Point to directory containing pipeline output
# Set variables for bash
Sys.setenv(QIIME_DIR = qiime.dir)
```
NOTE: If you ran the "count-reads" script, you can skip this step.
This should only be run once; if hanging at this step, you may need to go back and delete files or skip to code chunk below
```{bash engine.opts='-l'}
# Extract count information from QIIME2 visualization object
# Unzip the files if not already done
cd "$QIIME_DIR"

for f in [123]*.qzv; do
     unzip $f -d ${f%.qzv}
done
unzip 4_denoised-stats.qzv -d 4_denoised-stats

```


```{r}

# Read TSVs
count.fs <- 
     list.files(qiime.dir,
                pattern = 'per-sample-fastq-counts.tsv|metadata.tsv',
                recursive = TRUE,
                full.names = TRUE)
test=count.fs[1]
split_result=unlist(str_split(test,"/"))

count.files=c(seq_along(count.fs))
for (i in seq_along(count.fs)) {
  f=count.fs[i]
  split_result=unlist(str_split(f,"/")) # unzipped qiime directories go /name-of-qzv/random-numbers/data/file.tsv
  dirName=split_result[length(split_result) - 3] # so I can access what step of the pipeline the file came from by going back 3
  f=read_delim(f)
  if (dirName=='4_denoised-table') {
    break # this directory shouldn't have been unzipped but in case it was, skip it 
  }
  if (dirName=='4_denoised-stats') {
    f=f[-1,] %>%
      mutate(sample_ID=`sample-id`) %>%
      dplyr::select(sample_ID,filtered,denoised,merged,`non-chimeric`) 
    
  } 
  else {
  colnames(f)=str_replace_all(colnames(f),fixed(" "),"_")
  f$reverse_sequence_count=NULL
  colnames(f)[2]=dirName }
  if (i==1) {
    count.files=f
  } else {
    count.files=left_join(count.files,f,by='sample_ID')
  }
}
count.files
names(count.files) <- c('sample', 
                         'raw',
                         'adapter_trim',
                         'primer_trim',
                        'filtered',
                        'denoised',
                        'merged',
                        'non_chimeric')
count.files
write.csv(count.files,file.path(qiime.dir,
                                'track-pipeline.csv'))

```
## Step 1) QC 
If you already ran 'count-reads', skip to here
```{r}
count.files=file.path(qiime.dir,
                      'track-pipeline.csv') %>%
  read.csv()
```

```{r}
count.files %>%
  pivot_longer(names_to = 'step',values_to = 'count',cols=c('raw',
                         'adapter_trim',
                         'primer_trim',
                        'filtered',
                        'denoised',
                        'merged',
                        'non_chimeric')) %>%
  mutate(label=ifelse(sample=='Undetermined','Undetermined','Sample'),
         step=factor(step,levels=c('raw',
                         'adapter_trim',
                         'primer_trim',
                        'filtered',
                        'denoised',
                        'merged',
                        'non_chimeric'))) %>%
  ggplot(aes(x = step, 
                       y = count, 
                       by = sample, 
                       group = sample)) +
     geom_line(alpha = 0.5) +
     facet_wrap(~label, 
                scales = 'free_y') +
     labs(x = 'Pipeline step', 
          y = 'Reads', 
          title = '[DATE] MiniSeq run') +
     theme_bw() +
     theme(axis.text.x = element_text(angle = 45, hjust = 1))
setwd(qiime.dir)
ggsave('QC_track-reads-plot.png')
```

## Step 2) Make phyloseq object

### ASV tables

A few notes on QIIME2 output:
- Features in the ASV table features are a hash instead of a DNA sequence
- The table is organized as features x samples instead of samples x features

We'll pull these using QIIME2R functions to extract information from QIIME2 artifacts, join them together, and re-arrange as samples x features.
```{r}
# if you haven't already set this variable to wherever you have the '4_denoised-table.qza', '4_denoised-seqs.qza', and 'track-pipeline.csv' files saved
# qiime.dir <- '/path/to/qiime-output-directory'
```

```{r}
qiime.asvtab <- 
     file.path(qiime.dir,
          '4_denoised-table.qza') %>% 
     read_qza()
```

```{r}
qiime.seqs <- 
     file.path(qiime.dir,
          '4_denoised-seqs.qza') %>% 
     read_qza()
```


```{r}
qiime.asvtab <- join_table_seqs(qiime.asvtab, qiime.seqs)
```

#### QC

We'll do a few quick QC steps here:
- First, we'll collapse sequences that are exact subsequences of each other with DADA2's `collapseNoMismatch` function.
- Second, we'll visualize the distribution of sequence lengths in the dataset.

```{r}
cat(ncol(qiime.asvtab), 'ASVs before collapsing\n')
qiime.asvtab <- dada2::collapseNoMismatch(qiime.asvtab)
cat(ncol(qiime.asvtab), 'ASVs after collapsing\n')
```

Visualize the distribution of sequence lengths

```{r}
lengths <- 
     data.frame(asv = colnames(qiime.asvtab),
                reads = colSums(qiime.asvtab)) |> 
     mutate(length = nchar(asv))

# Histogram of sequence lengths
ggplot(lengths, aes(x = length)) +
     geom_histogram(binwidth = 5, boundary = 0) +
     geom_vline(xintercept = c(10, 143), # Reported range of trnL length
                color = 'red', 
                linetype = 'dashed') +
     labs(x = 'ASV length (bp)', y = 'Count') +
     theme_bw() +
     scale_x_continuous(minor_breaks = seq(0, 250, 10), 
                        breaks = seq(0, 250, 50))
setwd(qiime.dir)
ggsave('QC_seq-lengths-histogram.png')
```

### Taxonomy table

Enter the path to the reference you'll be using:
```{r}
# EXAMPLE
parent='/Users/tjk30/Library/CloudStorage/Box-Box/project_davidlab/LAD_LAB_Personnel/Teresa_M/1_Infant-Metabarcoding/'
ref <- file.path(parent,'0_Methods', 'Reference','12SV5_Schneider_taxonomy.fasta')
```

The next step is different depending on whether you are processing 12SV5 or trnL data:
#### For trnL

```{r}
# Using modified assignSpecies function from DADA2
# (only modifies format of returned data, not underlying assignment)
taxtab.species <- MButils::assignSpecies_mod(qiime.asvtab, 
                                             refFasta = ref, 
                                             tryRC = TRUE)

```

```{r}
# Separate accession from species name in our current list of assignments
taxtab.species <- separate(taxtab.species, 
                           Species,
                           into = c('accession', 'taxon'),
                           sep = ' ',
                           extra = 'merge')

head(taxtab.species)
```
Now, look up full taxonomy for these assigned species using taxonomizr functions and SQL database.
```{r}
# How many ASVs unassigned?
unassigned <- taxtab$asv[is.na(taxtab.species$Species)]

# Percentage of sequence variants
cat(100*(1 - (length(unassigned)/dim(qiime.asvtab)[2])), '% ASVs have an assigment\n')

# Percentage of reads mapping to these unassigned species
cat('These ASVs cover', 100*(1-sum(qiime.asvtab[, unassigned])/sum(qiime.asvtab)), '% of sequence reads in the dataset')
```
For taxonomic assignment, we'll need a path to the SQL database of NCBI's taxonomy produced by R's taxonomizr package.  This is saved on Isilon (~70Gb).  You'll need to map the Isilon network drive to your computer and then point R to the right location.  On a Mac, this is below:

```{r}
sql <- '/Volumes/All_Staff/localreference/ncbi_taxonomy/accessionTaxa.sql'
```



```{r}
# Now look up full taxonomy
# First link accession to taxon ID
taxids <- 
     taxonomizr::accessionToTaxa(taxtab.species$accession,
                                 sql)
taxids
```

```{r}
# Then link taxon ID to full taxonomy
taxonomy.raw <- 
     taxonomizr::getRawTaxonomy(taxids, sql)
```

```{r}
# Pull desired levels from this structure
# Not working within getTaxonomy function
vars <- c("superkingdom", 
          "phylum", 
          "class", 
          "order", 
          "family", 
          "genus",
          "species",
          "subspecies",
          "varietas",
          "forma")

taxonomy <- data.frame(superkingdom = NULL,
                       phylum = NULL,
                       class = NULL,
                       order = NULL,
                       family = NULL,
                       genus = NULL,
                       species = NULL,
                       subspecies = NULL,
                       varietas = NULL,
                       forma = NULL)

# Define an empty row to be returned if no accession was looked up
empty <- rep(NA, 10)
names(empty) <- vars

acc <- function(i, taxonomy.raw, vars) {
     # If accession looked up, pull relevant columns and return it
     row.i <- 
          taxonomy.raw[[i]] %>% 
          t() %>% 
          data.frame() 
     
     # Pick columns we're interested in
     shared <- intersect(vars, names(row.i))
     row.i <- select(row.i, one_of(shared))
     row.i
}

# If not looked up, returne empty row
no_acc <- function() empty

for (i in seq_along(taxonomy.raw)){
     row.i <- 
          tryCatch(
               {
                    acc(i, taxonomy.raw, vars)
               }, 
               error = function(e) {
                    no_acc()
               }
          )

     taxonomy <- bind_rows(taxonomy, row.i)
}
```

```{r}
head(taxonomy)
```

```{r}
# Group these to their last common ancestor using taxonomizr's condenseTaxa function
ncol(qiime.asvtab)
assignments <- 
     taxonomizr::condenseTaxa(taxonomy,
                              groupings = taxtab.species$asv)
dim(assignments)
```

```{r}
# To what label are assignments made?
colSums(!is.na(assignments))/nrow(assignments)
```

#### for 12SV5
```{r}
# 12SV5 taxonomy assignment 
taxtab <-
      dada2::assignTaxonomy(qiime.asvtab,
                            taxLevels = c(
                              'kingdom',
                              'phylum',
                              'class',
                              'order',
                              'family',
                              'genus',
                              'species',
                              'subspecies'
                            ),
                            refFasta = ref,
                            tryRC = TRUE)
head(taxtab)
taxonomy=data.frame(taxtab)
```

```{r}
# How many ASVs unassigned?
unassigned <- taxonomy$asv[is.na(taxonomy$Species)]

# Percentage of sequence variants
cat(100*(1 - (length(unassigned)/dim(qiime.asvtab)[2])), '% ASVs have an assigment\n')

# Percentage of reads mapping to these unassigned species
cat('These ASVs cover', 100*(1-sum(qiime.asvtab[, unassigned])/sum(qiime.asvtab)), '% of sequence reads in the dataset')
```


```{r}
# Group these to their last common ancestor using taxonomizr's condenseTaxa function
ncol(qiime.asvtab)
assignments <- 
     taxonomizr::condenseTaxa(taxonomy,
                              groupings = row.names(taxonomy))
dim(assignments)
```

```{r}
# To what label are assignments made?
colSums(!is.na(assignments))/nrow(assignments)
```

### Make object

```{r}
ps <- 
     phyloseq(otu_table = otu_table(qiime.asvtab,
                                    taxa_are_rows = FALSE),
              tax_table = tax_table(assignments))

ps
```
# Step 3) Save
```{r}
setwd(qiime.dir)
ps %>%
  saveRDS(file='raw-ps.rds')
```

```{r}
setwd(qiime.dir)
ps =readRDS('raw-ps.rds')
```

 # Step 4) Add metadata
```{r}
samdf=here('sample-metadata.csv') %>% read.csv() # a .csv file where "Sample_ID" is the same as in the samplesheet.csv file. You may need to change the path:
# samdf=read.csv('/path/to/sample-metadata.csv')

row.names(samdf)=samdf$Sample_ID
sample_data(ps)=samdf
```

```{r}
ps %>%
  saveRDS(file=here('ps-wMetadata.rds'))
```

```{r}
ps=here('ps-wMetadata.rds') %>%
  readRDS()
```
# Step 5: QC
You will need a column labeled "type" with whether or not the sample is a "positive control", "negative control", "blank", or "sample". You will need those exact labels for this next code chunk to work:
```{r}
ps.controls <-
     ps %>% 
     subset_samples(type %in% c('blank',
                                'positive control', 
                                'negative control')) %>% 
     prune_taxa(taxa_sums(.) > 0, .)
ps.controls

taxtab.controls <- tax_table(ps.controls)@.Data
taxtab.controls=data.frame(taxtab.controls) %>% 
   mutate(label=ifelse(!is.na(species),species, # setting "name" to the lowest taxonomic level that was assigned 
                     ifelse(!is.na(genus),genus, # there is probably a much more elegant way to do this but oh well
                            ifelse(!is.na(family),family,
                                   ifelse(!is.na(order),order,phylum)))))

# Replace in object
tax_table(ps.controls) <- as.matrix(taxtab.controls)
taxtab.controls
p=ps.controls %>% 
     psmelt() %>% 
     ggplot(aes(x = Sample, y = Abundance, fill = label)) +
     geom_bar(stat = "identity", position = "stack") + 
     facet_wrap(~type, scales = 'free') +
     labs(x = 'Control', y = 'Number of reads', fill = 'ASV identity',
     title = 'SAGE 14-28mo lib2 12SV5') +
     theme_bw()
print(p)
ggsave(plot=p,filename=here('controls.png'))
```
